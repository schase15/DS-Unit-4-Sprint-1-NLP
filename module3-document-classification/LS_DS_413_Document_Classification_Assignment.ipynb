{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lambda School Data Science\n",
    "\n",
    "*Unit 4, Sprint 1, Module 3*\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Document Classification (Assignment)\n",
    "\n",
    "This notebook is for you to practice skills during lecture.\n",
    "\n",
    "Today's guided module project and assignment will be different. You already know how to do classification. You ready know how to extract features from documents. So? That means you're ready to combine and practice those skills in a kaggle competition. We we will open with a five minute sprint explaining the competition, and then give you 25 minutes to work. After those twenty five minutes are up, I will give a 5-minute demo an NLP technique that will help you with document classification (*and **maybe** the competition*).\n",
    "\n",
    "Today's all about having fun and practicing your skills.\n",
    "\n",
    "## Sections\n",
    "* <a href=\"#p1\">Part 1</a>: Text Feature Extraction & Classification Pipelines\n",
    "* <a href=\"#p2\">Part 2</a>: Latent Semantic Indexing\n",
    "* <a href=\"#p3\">Part 3</a>: Word Embeddings with Spacy\n",
    "* <a href=\"#p4\">Part 4</a>: Post Lecture Assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Feature Extraction & Classification Pipelines (Learn)\n",
    "<a id=\"p1\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "## Follow Along \n",
    "\n",
    "What you should be doing now:\n",
    "1. Join the Kaggle Competition\n",
    "2. Download the data\n",
    "3. Train a model (try using the pipe method I just demoed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Statements\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Competition Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# You may need to change the path\n",
    "train = pd.read_csv('./data/train.csv')\n",
    "test = pd.read_csv('./data/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>description</th>\n",
       "      <th>ratingCategory</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1321</td>\n",
       "      <td>\\nSometimes, when whisky is batched, a few lef...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3861</td>\n",
       "      <td>\\nAn uncommon exclusive bottling of a 6 year o...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>655</td>\n",
       "      <td>\\nThis release is a port version of Amrut’s In...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>555</td>\n",
       "      <td>\\nThis 41 year old single cask was aged in a s...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1965</td>\n",
       "      <td>\\nQuite herbal on the nose, with aromas of dri...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id                                        description  ratingCategory\n",
       "0  1321  \\nSometimes, when whisky is batched, a few lef...               1\n",
       "1  3861  \\nAn uncommon exclusive bottling of a 6 year o...               0\n",
       "2   655  \\nThis release is a port version of Amrut’s In...               1\n",
       "3   555  \\nThis 41 year old single cask was aged in a s...               1\n",
       "4  1965  \\nQuite herbal on the nose, with aromas of dri...               1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Look at head of data\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Pipeline Components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define components\n",
    "# TFIDFVectorizer includes a build in tokenizer\n",
    "\n",
    "# Vectorizer\n",
    "vect = TfidfVectorizer(stop_words = 'english', ngram_range= (1,2), min_df= 5)\n",
    "\n",
    "# Classifier model\n",
    "clf = RandomForestClassifier()\n",
    "\n",
    "# Define pipeline using components\n",
    "pipe = Pipeline([('vect', vect), ('clf', clf)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Your Search Space\n",
    "You're looking for both the best hyperparameters of your vectorizer and your classification model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   42.9s\n",
      "[Parallel(n_jobs=-1)]: Done  80 out of  80 | elapsed:  1.4min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score=nan,\n",
       "             estimator=Pipeline(memory=None,\n",
       "                                steps=[('vect',\n",
       "                                        TfidfVectorizer(analyzer='word',\n",
       "                                                        binary=False,\n",
       "                                                        decode_error='strict',\n",
       "                                                        dtype=<class 'numpy.float64'>,\n",
       "                                                        encoding='utf-8',\n",
       "                                                        input='content',\n",
       "                                                        lowercase=True,\n",
       "                                                        max_df=1.0,\n",
       "                                                        max_features=None,\n",
       "                                                        min_df=5,\n",
       "                                                        ngram_range=(1, 2),\n",
       "                                                        norm='l2',\n",
       "                                                        preprocessor=None,\n",
       "                                                        smooth_idf=True,\n",
       "                                                        stop_words='english',\n",
       "                                                        strip...\n",
       "                                                               min_samples_split=2,\n",
       "                                                               min_weight_fraction_leaf=0.0,\n",
       "                                                               n_estimators=100,\n",
       "                                                               n_jobs=None,\n",
       "                                                               oob_score=False,\n",
       "                                                               random_state=None,\n",
       "                                                               verbose=0,\n",
       "                                                               warm_start=False))],\n",
       "                                verbose=False),\n",
       "             iid='deprecated', n_jobs=-1,\n",
       "             param_grid={'clf__max_depth': (5, 10, 15, 20),\n",
       "                         'vect__max_df': (0.75, 1.0),\n",
       "                         'vect__min_df': (0.02, 0.05)},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=1)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define parameter grid to search\n",
    "# Define parameters to tune for each model by attaching the model name followed by double underscore\n",
    "\n",
    "parameters = {\n",
    "    'vect__max_df': (0.75, 1.0),\n",
    "    'vect__min_df': (0.02, 0.05),\n",
    "    'clf__max_depth':(5,10,15,20)\n",
    "}\n",
    "\n",
    "# Define grid search\n",
    "grid_search = GridSearchCV(pipe, parameters, cv=5, n_jobs=-1, verbose=1)\n",
    "\n",
    "# Fit grid search - using the description column (text) and trying to predict the ratingCategory\n",
    "grid_search.fit(train['description'], train['ratingCategory'])\n",
    "\n",
    "# Also try using Randomized CV instead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7274305482817751"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Look at the best accuracy\n",
    "grid_search.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make a Submission File\n",
    "*Note:* In a typical Kaggle competition, you are only allowed two submissions a day, so you only submit if you feel you cannot achieve higher test accuracy. For this competition the max daily submissions are capped at **20**. Submit for each demo and for your assignment. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictions on test sample\n",
    "pred = grid_search.predict(test['description'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save in Kaggle submission format\n",
    "submission = pd.DataFrame({'id': test['id'], 'ratingCategory':pred})\n",
    "submission['ratingCategory'] = submission['ratingCategory'].astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>ratingCategory</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3461</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2604</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3341</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3764</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2306</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id  ratingCategory\n",
       "0  3461               1\n",
       "1  2604               1\n",
       "2  3341               1\n",
       "3  3764               1\n",
       "4  2306               1"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make Sure the Category is an Integer\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number submission files so you can keep track\n",
    "subNumber = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save your Submission File\n",
    "# Best to Use an Integer or Timestamp for different versions of your model\n",
    "\n",
    "submission.to_csv(f'./data/submission{subNumber}.csv', index=False)\n",
    "subNumber += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenge\n",
    "\n",
    "You're trying to achieve a minimum of 70% Accuracy on your model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Latent Semantic Indexing (Learn)\n",
    "<a id=\"p2\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "## Follow Along\n",
    "1. Join the Kaggle Competition\n",
    "2. Download the data\n",
    "3. Train a model & try: \n",
    "    - Creating a Text Extraction & Classification Pipeline\n",
    "    - Tune the pipeline with a `GridSearchCV` or `RandomizedSearchCV`\n",
    "    - Add some Latent Semantic Indexing (lsi) into your pipeline. *Note:* You can grid search a nested pipeline, but you have to use double underscores ie `lsi__svd__n_components`\n",
    "4. Make a submission to Kaggle \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Pipeline Components\n",
    "- Truncated SVD is a method to reduce dimensionality, similar to PCA but can be used on sparse matrices\n",
    "- Can be used on the outputs of count/tfidf vectorizers. - in this case it is called latent semantic analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import\n",
    "\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "# Instantiate TruncatedSVD model\n",
    "svd = TruncatedSVD(n_components=100, # Suggested value to use for LSA \n",
    "                   algorithm='randomized',\n",
    "                   n_iter=10) # Number of iterations for randomized svd solver to run through"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Latent Semantic Indexing using vect and svd objects\n",
    "\n",
    "lsi = Pipeline([('vect', vect), ('svd', svd)])\n",
    "\n",
    "# Vectorizer\n",
    "vect = TfidfVectorizer(stop_words = 'english', ngram_range= (1,2), min_df= 5)\n",
    "\n",
    "# Classifier model\n",
    "clf = RandomForestClassifier()\n",
    "\n",
    "# Define final pipe with lsi pipe and clf\n",
    "\n",
    "pipe = Pipeline([('lsi', lsi), ('clf', clf)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Your Search Space\n",
    "You're looking for both the best hyperparameters of your vectorizer and your classification model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Parameter grid to search\n",
    "\n",
    "params = { \n",
    "    'lsi__svd__n_components': [10,100,250],\n",
    "    'lsi__vect__max_df':[.9, .95, 1.0],\n",
    "    'clf__n_estimators':[5,10,20]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 27 candidates, totalling 135 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=4)]: Done 135 out of 135 | elapsed:  4.3min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score=nan,\n",
       "             estimator=Pipeline(memory=None,\n",
       "                                steps=[('lsi',\n",
       "                                        Pipeline(memory=None,\n",
       "                                                 steps=[('vect',\n",
       "                                                         TfidfVectorizer(analyzer='word',\n",
       "                                                                         binary=False,\n",
       "                                                                         decode_error='strict',\n",
       "                                                                         dtype=<class 'numpy.float64'>,\n",
       "                                                                         encoding='utf-8',\n",
       "                                                                         input='content',\n",
       "                                                                         lowercase=True,\n",
       "                                                                         max_df=1.0,\n",
       "                                                                         max_features=None,\n",
       "                                                                         min_df=5,\n",
       "                                                                         ngram_range=(1,\n",
       "                                                                                      2),\n",
       "                                                                         norm='l2',\n",
       "                                                                         preprocessor=None,\n",
       "                                                                         smooth_...\n",
       "                                                               min_weight_fraction_leaf=0.0,\n",
       "                                                               n_estimators=100,\n",
       "                                                               n_jobs=None,\n",
       "                                                               oob_score=False,\n",
       "                                                               random_state=None,\n",
       "                                                               verbose=0,\n",
       "                                                               warm_start=False))],\n",
       "                                verbose=False),\n",
       "             iid='deprecated', n_jobs=4,\n",
       "             param_grid={'clf__n_estimators': [5, 10, 20],\n",
       "                         'lsi__svd__n_components': [10, 100, 250],\n",
       "                         'lsi__vect__max_df': [0.9, 0.95, 1.0]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=1)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define grid search\n",
    "grid_search = GridSearchCV(pipe,params, cv=5, n_jobs=-1, verbose=1)\n",
    "\n",
    "# Fit grid search\n",
    "# X is input text, y is target\n",
    "\n",
    "grid_search.fit(train['description'], train['ratingCategory'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7240084631890182"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Best score\n",
    "grid_search.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make a Submission File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictions on test sample\n",
    "pred = grid_search.predict(test['description'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Submission df\n",
    "submission = pd.DataFrame({'id': test['id'], 'ratingCategory':pred})\n",
    "submission['ratingCategory'] = submission['ratingCategory'].astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>ratingCategory</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3461</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2604</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3341</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3764</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2306</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id  ratingCategory\n",
       "0  3461               1\n",
       "1  2604               1\n",
       "2  3341               1\n",
       "3  3764               1\n",
       "4  2306               1"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make Sure the Category is an Integer\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save your Submission File\n",
    "# Best to Use an Integer or Timestamp for different versions of your model\n",
    "\n",
    "submission.to_csv(f'./data/submission{subNumber}.csv', index=False)\n",
    "subNumber += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenge\n",
    "\n",
    "Continue to apply Latent Semantic Indexing (LSI) to various datasets. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word Embeddings with Spacy (Learn)\n",
    "<a id=\"p3\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Follow Along"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply to your Dataset\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "from scipy.stats import randint\n",
    "\n",
    "import spacy\n",
    "\n",
    "## No need to hyperparameter tune word embeddings, would only be doing it for the classifier\n",
    "# param_dist = {\n",
    "    \n",
    "#     'max_depth' : randint(3,10),\n",
    "#     'min_samples_leaf': randint(2,15)\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set nlp model\n",
    "nlp = spacy.load('en_core_web_lg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to get vectors for each word in my documents\n",
    "\n",
    "def get_word_vectors(docs):\n",
    "    return [nlp(doc).vector for doc in docs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply function to get all word vectors\n",
    "\n",
    "X = get_word_vectors(train['description'])\n",
    "\n",
    "# Make sure result is same length as the original list\n",
    "len(X) == len(train['description'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define classifier to use\n",
    "clf = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
       "                       criterion='gini', max_depth=None, max_features='auto',\n",
       "                       max_leaf_nodes=None, max_samples=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                       n_jobs=None, oob_score=False, random_state=None,\n",
       "                       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit classifier\n",
    "# X is the list of vectors from spacy, y is target\n",
    "\n",
    "clf.fit(X, train['ratingCategory'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get score for training data\n",
    "clf.score(X, train['ratingCategory'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Best submission - 80 on kaggle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make a Submission File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create word vectors for test set\n",
    "X_test = get_word_vectors(test['description'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Predicitons for submission\n",
    "test['ratingCategory'] = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create submission df\n",
    "submission = pd.DataFrame({'id': test['id'], 'ratingCategory':test['ratingCategory']})\n",
    "\n",
    "# Convert prediction to integer\n",
    "submission['ratingCategory'] = submission['ratingCategory'].astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>ratingCategory</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3461</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2604</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3341</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3764</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2306</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id  ratingCategory\n",
       "0  3461               1\n",
       "1  2604               1\n",
       "2  3341               1\n",
       "3  3764               1\n",
       "4  2306               1"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make Sure the Category is an Integer\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save your Submission File\n",
    "# Best to Use an Integer or Timestamp for different versions of your model\n",
    "\n",
    "submission.to_csv(f'./data/submission{subNumber}.csv', index=False)\n",
    "subNumber += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenge\n",
    "\n",
    "What you should be doing now:\n",
    "1. Join the Kaggle Competition\n",
    "2. Download the data\n",
    "3. Train a model & try: \n",
    "    - Creating a Text Extraction & Classification Pipeline\n",
    "    - Tune the pipeline with a `GridSearchCV` or `RandomizedSearchCV`\n",
    "    - Add some Latent Semantic Indexing (lsi) into your pipeline. *Note:* You can grid search a nested pipeline, but you have to use double underscores ie `lsi__svd__n_components`\n",
    "    - Try to extract word embeddings with Spacy and use those embeddings as your features for a classification model.\n",
    "4. Make a submission to Kaggle "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Balancing the classes by up/down sampling - didn't end up helping, 76 on kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Look at distribution\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "sns.countplot(x='ratingCategory', data=train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    2881\n",
       "0    1141\n",
       "2      65\n",
       "Name: ratingCategory, dtype: int64"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Very few 2, mostly 1's and 0's\n",
    "\n",
    "train['ratingCategory'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Upsample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upsample, pull in equal amounts of each category\n",
    "\n",
    "from sklearn.utils import resample\n",
    "\n",
    "# Seperate the data into the three different target categories\n",
    "zero = train[train['ratingCategory'] == 0] \n",
    "one = train[train['ratingCategory'] == 1]\n",
    "two = train[train['ratingCategory'] == 2]\n",
    "\n",
    "# upsample for the zeros and the twos\n",
    "zero_upsampled = resample(zero,\n",
    "                         replace= True,\n",
    "                         n_samples= one.shape[0]\n",
    "                         )\n",
    "\n",
    "two_upsampled = resample(two,\n",
    "                        replace= True,\n",
    "                        n_samples= one.shape[0]\n",
    "                        )\n",
    "\n",
    "# Put all three samples together into a dataframe to process\n",
    "df_upsampled = pd.concat([one, zero_upsampled, two_upsampled])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>description</th>\n",
       "      <th>ratingCategory</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1321</td>\n",
       "      <td>\\nSometimes, when whisky is batched, a few lef...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>655</td>\n",
       "      <td>\\nThis release is a port version of Amrut’s In...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>555</td>\n",
       "      <td>\\nThis 41 year old single cask was aged in a s...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1965</td>\n",
       "      <td>\\nQuite herbal on the nose, with aromas of dri...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3190</td>\n",
       "      <td>\\nCooley produced some great Irish single malt...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id                                        description  ratingCategory\n",
       "0  1321  \\nSometimes, when whisky is batched, a few lef...               1\n",
       "2   655  \\nThis release is a port version of Amrut’s In...               1\n",
       "3   555  \\nThis 41 year old single cask was aged in a s...               1\n",
       "4  1965  \\nQuite herbal on the nose, with aromas of dri...               1\n",
       "5  3190  \\nCooley produced some great Irish single malt...               1"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Look at the resulting df\n",
    "df_upsampled.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    2881\n",
       "1    2881\n",
       "0    2881\n",
       "Name: ratingCategory, dtype: int64"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make sure the classes are balanced\n",
    "df_upsampled['ratingCategory'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use random forest classifier and spacy to do word embedding\n",
    "\n",
    "# Set nlp model\n",
    "nlp = spacy.load('en_core_web_lg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function to get vectors for each word in my documents\n",
    "\n",
    "def get_word_vectors(docs):\n",
    "    return [nlp(doc).vector for doc in docs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply function to get all word vectors\n",
    "\n",
    "X = get_word_vectors(df_upsampled['description'])\n",
    "\n",
    "# Make sure result is same length as the original list\n",
    "len(X) == len(df_upsampled['description'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
       "                       criterion='gini', max_depth=None, max_features='auto',\n",
       "                       max_leaf_nodes=None, max_samples=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                       n_jobs=None, oob_score=False, random_state=None,\n",
       "                       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit classifier\n",
    "clf.fit(X, df_upsampled['ratingCategory'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get score\n",
    "clf.score(X, df_upsampled['ratingCategory'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply function to get all word vectors for regular training dataset\n",
    "\n",
    "X = get_word_vectors(train['description'])\n",
    "\n",
    "# Make sure result is same length as the original list\n",
    "len(X) == len(train['description'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9853193051137754"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get score for original training data\n",
    "clf.score(X, train['ratingCategory'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Create submission for rfc with word embedding and balanced classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create word vectors for test set\n",
    "X_test = get_word_vectors(test['description'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Predicitons for submission\n",
    "test['ratingCategory'] = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create submission df\n",
    "submission = pd.DataFrame({'id': test['id'], 'ratingCategory':test['ratingCategory']})\n",
    "\n",
    "# Convert prediction to integer\n",
    "submission['ratingCategory'] = submission['ratingCategory'].astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>ratingCategory</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3461</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2604</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3341</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3764</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2306</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id  ratingCategory\n",
       "0  3461               1\n",
       "1  2604               1\n",
       "2  3341               1\n",
       "3  3764               1\n",
       "4  2306               1"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make Sure the Category is an Integer\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save your Submission File\n",
    "# Best to Use an Integer or Timestamp for different versions of your model\n",
    "\n",
    "submission.to_csv(f'./data/submission{subNumber}.csv', index=False)\n",
    "subNumber += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gave me a worse result in the Kaggle competition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Try using XGBoost - Gave me 76% on the kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set nlp model\n",
    "nlp = spacy.load('en_core_web_lg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function to get vectors for each word in my documents\n",
    "\n",
    "def get_word_vectors(docs):\n",
    "    return [nlp(doc).vector for doc in docs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting xgboost\n",
      "  Downloading xgboost-1.1.0-py3-none-macosx_10_13_x86_64.macosx_10_14_x86_64.macosx_10_15_x86_64.whl (1.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.1 MB 782 kB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy in /Users/stevenchase/opt/anaconda3/envs/U4-S1-NLP/lib/python3.7/site-packages (from xgboost) (1.18.4)\n",
      "Requirement already satisfied: scipy in /Users/stevenchase/opt/anaconda3/envs/U4-S1-NLP/lib/python3.7/site-packages (from xgboost) (1.4.1)\n",
      "Installing collected packages: xgboost\n",
      "Successfully installed xgboost-1.1.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import XGBoost classifier\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define classifier\n",
    "clf = XGBClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XGBClassifier needs the vectors as a matrix - turn list into np array\n",
    "X = np.array(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints='',\n",
       "              learning_rate=0.300000012, max_delta_step=0, max_depth=6,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "              n_estimators=100, n_jobs=0, num_parallel_tree=1,\n",
       "              objective='multi:softprob', random_state=0, reg_alpha=0,\n",
       "              reg_lambda=1, scale_pos_weight=None, subsample=1,\n",
       "              tree_method='exact', validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit classifier\n",
    "clf.fit(X, train['ratingCategory'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Create submission for xgbclassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create word vectors for test set\n",
    "X_test = get_word_vectors(test['description'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XGBClassifier needs input as matrix\n",
    "X_test = np.array(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Predicitons for submission\n",
    "test['ratingCategory'] = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create submission df\n",
    "submission = pd.DataFrame({'id': test['id'], 'ratingCategory':test['ratingCategory']})\n",
    "\n",
    "# Convert prediction to integer\n",
    "submission['ratingCategory'] = submission['ratingCategory'].astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>ratingCategory</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3461</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2604</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3341</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3764</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2306</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id  ratingCategory\n",
       "0  3461               1\n",
       "1  2604               1\n",
       "2  3341               1\n",
       "3  3764               1\n",
       "4  2306               1"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make Sure the Category is an Integer\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save your Submission File\n",
    "# Best to Use an Integer or Timestamp for different versions of your model\n",
    "\n",
    "submission.to_csv(f'./data/submission{subNumber}.csv', index=False)\n",
    "subNumber += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Do binary classifier, take out the 2 values, balance remaining classes\n",
    "- worse, 75% on kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upsample zero class, get rid of the two class\n",
    "\n",
    "minority = train[train['ratingCategory'] == 0]\n",
    "majority = train[train['ratingCategory'] == 1]\n",
    "\n",
    "df_minority_upsampled = resample(minority,\n",
    "                                 replace=True,\n",
    "                                 n_samples=majority.shape[0]\n",
    "                                )\n",
    "\n",
    "df_upsampled = pd.concat([majority, df_minority_upsampled])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(x='ratingCategory', data=df_upsampled);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use random forest classifier and spacy to do word embedding\n",
    "\n",
    "# Set nlp model\n",
    "nlp = spacy.load('en_core_web_lg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function to get vectors for each word in my documents\n",
    "\n",
    "def get_word_vectors(docs):\n",
    "    return [nlp(doc).vector for doc in docs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply function to get all word vectors\n",
    "\n",
    "X = get_word_vectors(df_upsampled['description'])\n",
    "\n",
    "# Make sure result is same length as the original list\n",
    "len(X) == len(df_upsampled['description'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Classifier\n",
    "clf = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
       "                       criterion='gini', max_depth=None, max_features='auto',\n",
       "                       max_leaf_nodes=None, max_samples=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                       n_jobs=None, oob_score=False, random_state=None,\n",
       "                       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit classifier\n",
    "clf.fit(X, df_upsampled['ratingCategory'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply function to get all word vectors for regular training dataset\n",
    "\n",
    "X = get_word_vectors(train['description'])\n",
    "\n",
    "# Make sure result is same length as the original list\n",
    "len(X) == len(train['description'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9681918277465134"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get score\n",
    "clf.score(X, train['ratingCategory'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Create submission for binary classifier - Random forest and word embedding with spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create word vectors for test set\n",
    "X_test = get_word_vectors(test['description'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Predicitons for submission\n",
    "test['ratingCategory'] = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create submission df\n",
    "submission = pd.DataFrame({'id': test['id'], 'ratingCategory':test['ratingCategory']})\n",
    "\n",
    "# Convert prediction to integer\n",
    "submission['ratingCategory'] = submission['ratingCategory'].astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>ratingCategory</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3461</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2604</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3341</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3764</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2306</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id  ratingCategory\n",
       "0  3461               1\n",
       "1  2604               1\n",
       "2  3341               1\n",
       "3  3764               1\n",
       "4  2306               1"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make Sure the Category is an Integer\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save your Submission File\n",
    "# Best to Use an Integer or Timestamp for different versions of your model\n",
    "\n",
    "submission.to_csv(f'./data/submission{subNumber}.csv', index=False)\n",
    "subNumber += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### XGBClassifier, Tf idf vectorizer, LSI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define objects: vectorizer, classifier, Truncated SVD\n",
    "vect = TfidfVectorizer(stop_words = 'english', ngram_range= (1,2), min_df= 5)\n",
    "svd = TruncatedSVD(n_components=100, # Just here for demo. \n",
    "                   algorithm='randomized',\n",
    "                   n_iter=10)\n",
    "clf = XGBClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define pipes\n",
    "\n",
    "lsi = Pipeline([('vect', vect), ('svd', svd)])\n",
    "\n",
    "# Define final pipe with lsi pipe and clf from above, \n",
    "\n",
    "pipe = Pipeline([('lsi', lsi), ('clf', clf)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Parameter grid to search\n",
    "\n",
    "params = { \n",
    "    'lsi__svd__n_components': [10,100,250],\n",
    "    'lsi__vect__max_df':[.9, .95, 1.0]\n",
    "#     'clf__n_estimators':[5,10,20]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  45 out of  45 | elapsed:  7.3min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score=nan,\n",
       "             estimator=Pipeline(memory=None,\n",
       "                                steps=[('lsi',\n",
       "                                        Pipeline(memory=None,\n",
       "                                                 steps=[('vect',\n",
       "                                                         TfidfVectorizer(analyzer='word',\n",
       "                                                                         binary=False,\n",
       "                                                                         decode_error='strict',\n",
       "                                                                         dtype=<class 'numpy.float64'>,\n",
       "                                                                         encoding='utf-8',\n",
       "                                                                         input='content',\n",
       "                                                                         lowercase=True,\n",
       "                                                                         max_df=1.0,\n",
       "                                                                         max_features=None,\n",
       "                                                                         min_df=5,\n",
       "                                                                         ngram_range=(1,\n",
       "                                                                                      2),\n",
       "                                                                         norm='l2',\n",
       "                                                                         preprocessor=None,\n",
       "                                                                         smooth_...\n",
       "                                                      random_state=None,\n",
       "                                                      reg_alpha=None,\n",
       "                                                      reg_lambda=None,\n",
       "                                                      scale_pos_weight=None,\n",
       "                                                      subsample=None,\n",
       "                                                      tree_method=None,\n",
       "                                                      validate_parameters=None,\n",
       "                                                      verbosity=None))],\n",
       "                                verbose=False),\n",
       "             iid='deprecated', n_jobs=-1,\n",
       "             param_grid={'lsi__svd__n_components': [10, 100, 250],\n",
       "                         'lsi__vect__max_df': [0.9, 0.95, 1.0]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=1)"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define grid search\n",
    "grid_search = GridSearchCV(pipe, params, cv=5, n_jobs=-1, verbose=1)\n",
    "\n",
    "# Fit grid search\n",
    "grid_search.fit(train['description'], train['ratingCategory'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7386894626114384"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Best score\n",
    "grid_search.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Post Lecture Assignment\n",
    "<a id=\"p4\"></a>\n",
    "\n",
    "Your primary assignment this afternoon is to achieve a minimum of 70% accuracy on the Kaggle competition. Once you have achieved 70% accuracy, please work on the following: \n",
    "\n",
    "1. Research \"Sentiment Analysis\". Provide answers in markdown to the following questions: \n",
    "    - What is \"Sentiment Analysis\"? \n",
    "        - Sentiment Analysis is a method that extracts the underlying sentiment of the text, whether the text is positive, neutral or negative. \n",
    "    - Is Document Classification different than \"Sentiment Analysis\"? Provide evidence for your response\n",
    "        - Document classification predicts which predefined class or category a document belongs in. As an example, in the whiskey reviews, we are classifying the reviews (documents) as either a 0, 1 or 2 rating. We are doing this be examining the just the words in the text. Sentiment analysis examines the emotion (semtiment) behind the review. It can tell you whether the review in positive, neutral or negative. In a business application, document classification can determine which department the document should go to, sentiment analysis would tell you whether it was a positive, neutral or negative document.\n",
    "    - How do create labeled sentiment data? Are those labels really sentiment?\n",
    "        - \n",
    "    - What are common applications of sentiment analysis?\n",
    "2. Research our why word embeddings worked better for the lecture notebook than on the whiskey competition.\n",
    "    - This [text classification documentation](https://developers.google.com/machine-learning/guides/text-classification/step-2-5) from Google might be of interest\n",
    "    - Neural Networks are becoming more popular for document classification. Why is that the case?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "U4-S1-NLP (Python3)",
   "language": "python",
   "name": "u4-s1-nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
